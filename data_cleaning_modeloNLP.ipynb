{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import RFE\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import sys\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "from os.path import join\n",
    "from random import shuffle, sample\n",
    "from sklearn.utils import shuffle\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIRVE PARA TOKENIZAR\n",
    "def to_single_message_format(gamefile):\n",
    "    messages = []\n",
    "    with open(gamefile) as inh:\n",
    "        for ln in inh:\n",
    "            conversation = json.loads(ln)\n",
    "            for msg, sender_label, receiver_label, score_delta \\\n",
    "                in zip(conversation['messages'],conversation['sender_labels'], \\\n",
    "                    conversation['receiver_labels'], conversation['game_score_delta']):\n",
    "                messages.append({'message': msg, 'receiver_annotation': receiver_label,\\\n",
    "                    'sender_annotation':sender_label, 'score_delta': int(score_delta)})\n",
    "    shuffle(messages)    \n",
    "    return messages\n",
    "\n",
    "def write_single_messages(messages, outfile):\n",
    "    with open(outfile, \"w\") as outh:\n",
    "        for msg in messages:\n",
    "            outh.write(json.dumps(msg)+'\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ROOT = 'data/'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train (13132,)\n",
      "Distribución de clases en el conjunto de entrenamiento:\n",
      "True     12541\n",
      "False      591\n",
      "Name: sender_annotation, dtype: int64\n",
      "Distribución de clases en el conjunto de test:\n",
      "True     2501\n",
      "False     240\n",
      "Name: sender_annotation, dtype: int64\n",
      "Distribución de clases en el conjunto de validación:\n",
      "True     1360\n",
      "False      56\n",
      "Name: sender_annotation, dtype: int64\n",
      "Distribución de la clases en el nuevo conjunto de entrenamiento:\n",
      "True     12541\n",
      "False    12541\n",
      "Name: sender_annotation, dtype: int64\n",
      "Y_train nuevo (25082,)\n",
      "Dimensiones de df_train_copy: (25082, 4)\n",
      "Dimensiones de df_test_copy: (2741, 4)\n",
      "Dimensiones de df_validation_copy: (1416, 4)\n",
      "Dimensiones de y_train: (25082,)\n",
      "*******************************:\n",
      "Dimensiones de df_train: (25082, 4)\n"
     ]
    }
   ],
   "source": [
    "#LECTURA DE DATOS\n",
    "df_train = to_single_message_format(join(ROOT, 'train.jsonl'))\n",
    "df_test = to_single_message_format(join(ROOT, 'test.jsonl'))\n",
    "df_validation = to_single_message_format(join(ROOT, 'validation.jsonl'))\n",
    "#TRANSFORMACION A DATAFRAME\n",
    "df_train_copy = pd.DataFrame(df_train)\n",
    "df_test_copy = pd.DataFrame(df_test)\n",
    "df_validation_copy = pd.DataFrame(df_validation)\n",
    "y_train = df_train_copy['sender_annotation']\n",
    "print('Y_train',y_train.shape)\n",
    "\n",
    "# Revisar la distribución de clases en el conjunto de entrenamiento\n",
    "print(\"Distribución de clases en el conjunto de entrenamiento:\")\n",
    "print(df_train_copy['sender_annotation'].value_counts())\n",
    "\n",
    "# Revisar la distribución de clases en el conjunto de validación\n",
    "print(\"Distribución de clases en el conjunto de test:\")\n",
    "print(df_test_copy['sender_annotation'].value_counts())\n",
    "\n",
    "# Revisar la distribución de clases en el conjunto de validación\n",
    "print(\"Distribución de clases en el conjunto de validación:\")\n",
    "print(df_validation_copy['sender_annotation'].value_counts())\n",
    "\n",
    "\n",
    "#EXISTE UN DESBALANCEO DE CLASES, POR LO QUE SE DEBE HACER UN SOBREMUESTREO DE LA CLASE MINORITARIA\n",
    "# Separar los datos por clases\n",
    "df_majority = df_train_copy[df_train_copy['sender_annotation'] == True]\n",
    "df_minority = df_train_copy[df_train_copy['sender_annotation'] == False]\n",
    "# Sobremuestrear la clase minoritaria\n",
    "df_minority_oversampled = df_minority.sample(len(df_majority), replace=True)  # Replicar los datos de la clase minoritaria\n",
    "# Combinar la clase mayoritaria con la clase minoritaria sobremuestreada\n",
    "df_oversampled = pd.concat([df_majority, df_minority_oversampled])\n",
    "# Barajar o sedordena los datos\n",
    "df_oversampled = shuffle(df_oversampled) \n",
    "\n",
    "# Ahora puedes proceder a tokenizar y preparar estos datos para el entrenamiento como lo hiciste anteriormente\n",
    "# Revisar la nueva distribución de clases en el conjunto de entrenamiento\n",
    "print(\"Distribución de la clases en el nuevo conjunto de entrenamiento:\")\n",
    "print(df_oversampled['sender_annotation'].value_counts())\n",
    "\n",
    "df_train_copy = df_oversampled\n",
    "y_train = df_train_copy['sender_annotation']\n",
    "print('Y_train nuevo',y_train.shape)\n",
    "\n",
    "\n",
    "print(\"Dimensiones de df_train_copy:\", df_train_copy.shape)\n",
    "print(\"Dimensiones de df_test_copy:\", df_test_copy.shape)\n",
    "print(\"Dimensiones de df_validation_copy:\", df_validation_copy.shape)\n",
    "print(\"Dimensiones de y_train:\", y_train.shape)\n",
    "print(\"*******************************:\")\n",
    "print(\"Dimensiones de df_train:\", df_train_copy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Germany!\\n\\nJust the person I want to speak with. I have a somewhat crazy idea that I’ve always wanted to try with I/G, but I’ve never actually convinced the other guy to try it. And, what’s worse, it might make you suspicious of me. \\n\\nSo...do I suggest it?\\n\\nI’m thinking that this is a low stakes game, not a tournament or anything, and an interesting and unusual move set might make it more fun? That’s my hope anyway.\\n\\nWhat is your appetite like for unusual and crazy?',\n",
       " 'receiver_annotation': True,\n",
       " 'sender_annotation': True,\n",
       " 'score_delta': 0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train_copy[0]\n",
    "#df_test_copy[0]\n",
    "#df_train_copy\n",
    "df_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREACION DEL MODELO\n",
    "from transformers import BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de input_ids: torch.Size([25082, 256])\n",
      "Dimensiones de attention_masks: torch.Size([25082, 256])\n",
      "Dimensiones de y_train_tensor: (25082,)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def encode_messages(messages, max_length):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for message in messages:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            message,                      \n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Concatenar los tensores\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# Aplicar la función de codificación a tus mensajes\n",
    "messages = df_train_copy['message'].tolist()\n",
    "input_ids, attention_masks = encode_messages(messages, max_length=256)\n",
    "\n",
    "# Comprobación de las dimensiones\n",
    "print(\"Dimensiones de input_ids:\", input_ids.shape)\n",
    "print(\"Dimensiones de attention_masks:\", attention_masks.shape)\n",
    "print(\"Dimensiones de y_train_tensor:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "False\n",
      "<class 'list'>\n",
      "True\n",
      "[\"{'message': 'Germany!\\\\n\\\\nJust the person I want to speak with. I have a somewhat crazy idea that I’ve always wanted to try with I/G, but I’ve never actually convinced the other guy to try it. And, what’s worse, it might make you suspicious of me. \\\\n\\\\nSo...do I suggest it?\\\\n\\\\nI’m thinking that this is a low stakes game, not a tournament or anything, and an interesting and unusual move set might make it more fun? That’s my hope anyway.\\\\n\\\\nWhat is your appetite like for unusual and crazy?', 'receiver_annotation': True, 'sender_annotation': True, 'score_delta': 0}\", '{\\'message\\': \"You\\'ve whet my appetite, Italy. What\\'s the suggestion?\", \\'receiver_annotation\\': True, \\'sender_annotation\\': True, \\'score_delta\\': 0}', \"{'message': '👍', 'receiver_annotation': True, 'sender_annotation': True, 'score_delta': 0}\", '{\\'message\\': \"It seems like there are a lot of ways that could go wrong...I don\\'t see why France would see you approaching/taking Munich--while I do nothing about it--and not immediately feel skittish\", \\'receiver_annotation\\': True, \\'sender_annotation\\': True, \\'score_delta\\': 0}', \"{'message': 'Yeah, I can’t say I’ve tried it and it works, cause I’ve never tried it or seen it. But how I think it would work is (a) my Spring move looks like an attack on Austria, so it would not be surprising if you did not cover Munich. Then (b) you build two armies, which looks like we’re really at war and you’re going to eject me. Then we launch the attack in Spring. So there is really no part of this that would raise alarm bells with France.\\\\n\\\\nAll that said, I’ve literally never done it before, and it does involve risk for you, so I’m not offended or concerned if it’s just not for you. I’m happy to play more conventionally too. Up to you.', 'receiver_annotation': 'NOANNOTATION', 'sender_annotation': True, 'score_delta': 0}\"]\n"
     ]
    }
   ],
   "source": [
    "print(type(df_train))  # Debería ser <class 'list'>\n",
    "print(all(isinstance(item, str) for item in df_train))  # Todos los elementos deben ser cadenas de texto\n",
    "df_train = [str(message) for message in df_train]  # Convertir todos los elementos a cadenas de texto\n",
    "print(type(df_train))  # Debería ser <class 'list'>\n",
    "print(all(isinstance(item, str) for item in df_train))  # Todos los elementos deben ser cadenas de texto\n",
    "print(df_train[:5])  # Imprime los primeros 5 elementos para verificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de input_ids: torch.Size([25082, 256])\n",
      "Dimensiones de attention_masks: torch.Size([25082, 256])\n",
      "Dimensiones de y_train_tensor: torch.Size([25082])\n"
     ]
    }
   ],
   "source": [
    "y_train\n",
    "# Si y_train es una serie de Pandas (por ejemplo, una columna de DataFrame)\n",
    "y_train_tensor = torch.tensor(y_train.values).long()\n",
    "y_train_tensor.shape\n",
    "\n",
    "print(\"Dimensiones de input_ids:\", input_ids.shape)\n",
    "print(\"Dimensiones de attention_masks:\", attention_masks.shape)\n",
    "print(\"Dimensiones de y_train_tensor:\", y_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorDataset\n",
    "#es una clase de PyTorch que encapsula tensores en un conjunto de datos. \n",
    "#En tu caso, estos tensores serán los input_ids y attention_masks generados por el tokenizador,\n",
    "#así como las etiquetas de tus datos (y_train).\n",
    "from torch.utils.data import TensorDataset\n",
    "train_dataset = TensorDataset(input_ids, attention_masks, y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader\n",
    "#DataLoader es una clase que proporciona un iterable sobre el conjunto de datos. Con DataLoader, puedes especificar \n",
    "#el tamaño del lote (batch size), si los datos deben ser mezclados, y otros parámetros que son útiles durante el entrenamiento.\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de train_dataloader: <torch.utils.data.dataset.TensorDataset object at 0x0000025DFFF52410>\n",
      "Dimensiones de train_dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000025DFFD78190>\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensiones de train_dataloader:\", train_dataset)\n",
    "print(\"Dimensiones de train_dataloader:\", train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.8\n",
      "NVIDIA GeForce RTX 3070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())  # Debería ser True si CUDA está disponible\n",
    "print(torch.version.cuda)        # Debería mostrar la versión de CUDA\n",
    "print(torch.cuda.get_device_name(0))  # Muestra el nombre de tu GPU CUDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n"
     ]
    }
   ],
   "source": [
    "#CONFIGURACION DEL MODELO BERT\n",
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA disponible. Dispositivos CUDA: 1\n",
      "Nombre del dispositivo CUDA: NVIDIA GeForce RTX 3070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#C:\\Users\\nobce\\AppData\\Local\\Temp\\cuda\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA disponible. Dispositivos CUDA:\", torch.cuda.device_count())\n",
    "    print(\"Nombre del dispositivo CUDA:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA no está disponible.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Cargar el modelo preentrenado de BERT\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased', # Usa la versión base de BERT\n",
    "    num_labels = 2,     # Número de etiquetas de salida (por ejemplo, 2 para clasificación binaria)\n",
    "    output_attentions = False, # Si el modelo debe retornar las atenciones\n",
    "    output_hidden_states = False, # Si el modelo debe retornar todos los estados ocultos\n",
    ")\n",
    "\n",
    "# Mover el modelo al dispositivo adecuado (GPU o CPU)\n",
    "model.to(device)  # Ejemplo: device puede ser 'cuda' para GPU o 'cpu' para CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, batch in enumerate(train_dataloader):\n",
    "    # Mover el lote al dispositivo\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    b_input_ids = b_input_ids.to(device)\n",
    "    b_input_mask = b_input_mask.to(device)\n",
    "    b_labels = b_labels.to(device)\n",
    "\n",
    "    # Realizar pasos de entrenamiento...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el optimizador y la Función de Pérdida\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # tasa de aprendizaje\n",
    "                  eps = 1e-8 # epsilon\n",
    "                 )\n",
    "\n",
    "# Definir la función de pérdida\n",
    "from torch.nn import CrossEntropyLoss\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.24340122679013246\n",
      "Average training loss: 0.03561993770310845\n"
     ]
    }
   ],
   "source": [
    "# Número de épocas de entrenamiento\n",
    "epochs = 2\n",
    "\n",
    "# Bucle para cada época\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Entrenamiento\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        # Desempacar el lote del dataloader y cargarlo al dispositivo adecuado\n",
    "        b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Limpiar gradientes existentes\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Ejecutar el modelo para obtener logits\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "        # Calcular la pérdida\n",
    "        loss = loss_fn(outputs.logits, b_labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Retropropagación para calcular gradientes\n",
    "        loss.backward()\n",
    "\n",
    "        # Actualizar los parámetros del modelo\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calcular la pérdida promedio sobre la época\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Average training loss: {avg_train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\nobce\\\\OneDrive\\\\Documentos\\\\PRUEBA CIENCITIFICO DATOS\\\\2024_acl_diplomacy-master\\\\modelo_de_entrenamiento_guardado\\\\tokenizer_config.json',\n",
       " 'C:\\\\Users\\\\nobce\\\\OneDrive\\\\Documentos\\\\PRUEBA CIENCITIFICO DATOS\\\\2024_acl_diplomacy-master\\\\modelo_de_entrenamiento_guardado\\\\special_tokens_map.json',\n",
       " 'C:\\\\Users\\\\nobce\\\\OneDrive\\\\Documentos\\\\PRUEBA CIENCITIFICO DATOS\\\\2024_acl_diplomacy-master\\\\modelo_de_entrenamiento_guardado\\\\vocab.txt',\n",
       " 'C:\\\\Users\\\\nobce\\\\OneDrive\\\\Documentos\\\\PRUEBA CIENCITIFICO DATOS\\\\2024_acl_diplomacy-master\\\\modelo_de_entrenamiento_guardado\\\\added_tokens.json')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GUARDA EL MODELO DE ENTRENAMIENTO\n",
    "model.save_pretrained(r\"C:\\Users\\nobce\\OneDrive\\Documentos\\PRUEBA CIENCITIFICO DATOS\\2024_acl_diplomacy-master\\modelo_de_entrenamiento_guardado\")\n",
    "tokenizer.save_pretrained(r\"C:\\Users\\nobce\\OneDrive\\Documentos\\PRUEBA CIENCITIFICO DATOS\\2024_acl_diplomacy-master\\modelo_de_entrenamiento_guardado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizamos los mensajes de la data de validación\n",
    "validation_inputs, validation_masks = encode_messages(df_validation_copy['message'].tolist(), max_length=256)\n",
    "# Se convierte las etiquetas en tensores\n",
    "validation_labels = torch.tensor(df_validation_copy['sender_annotation'].values).long()  # Asegúrate de que 'label' es el nombre de tu columna de etiquetas\n",
    "\n",
    "# Crea el TensorDataset\n",
    "validation_dataset = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "# Crea el DataLoader\n",
    "batch_size = 16  # Puedes ajustar esto según las necesidades de tu modelo y hardware\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.16      0.12        56\n",
      "           1       0.96      0.94      0.95      1360\n",
      "\n",
      "    accuracy                           0.91      1416\n",
      "   macro avg       0.53      0.55      0.54      1416\n",
      "weighted avg       0.93      0.91      0.92      1416\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   9   47]\n",
      " [  80 1280]]\n",
      "Accuracy Score:\n",
      "0.9103107344632768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Función para evaluar el modelo\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()  # Poner el modelo en modo de evaluación\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            b_input_ids = b_input_ids.to(device)\n",
    "            b_input_mask = b_input_mask.to(device)\n",
    "            b_labels = b_labels.to(device)\n",
    "\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "            logits = outputs.logits\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            predictions.append(logits)\n",
    "            true_labels.append(label_ids)\n",
    "\n",
    "    flat_predictions = np.concatenate(predictions, axis=0)\n",
    "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "    flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "    return flat_predictions, flat_true_labels\n",
    "\n",
    "# Asumiendo que tienes un DataLoader para tus datos de validación/prueba\n",
    "predictions, true_labels = evaluate_model(model, validation_dataloader, device)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predictions))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, predictions))\n",
    "\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segun nuestro modelo, el accuracy es de 0.93, lo cual es bastante bueno, pero no es suficiente para nuestro modelo\n",
    "#lo cual es aconsajable ajustar learning rate o los epochs con mas tiempo \n",
    "\n",
    "#PRUEBA SOBRE EL CONJUNTO DE DATOS DE PRUEBA df_test_copy\n",
    "\n",
    "# Tokenizar los textos de prueba\n",
    "test_inputs, test_masks = encode_messages(df_test_copy['message'].tolist(), max_length=256)\n",
    "# Convertir las etiquetas de prueba en tensores\n",
    "test_labels = torch.tensor(df_test_copy['sender_annotation'].values).long()\n",
    "# Crear el TensorDataset\n",
    "test_dataset = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "# Crear el DataLoader\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)  # Ajusta el batch_size según sea necesario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.12      0.13       240\n",
      "           1       0.92      0.93      0.93      2501\n",
      "\n",
      "    accuracy                           0.86      2741\n",
      "   macro avg       0.53      0.53      0.53      2741\n",
      "weighted avg       0.85      0.86      0.86      2741\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  28  212]\n",
      " [ 165 2336]]\n",
      "Accuracy Score:\n",
      "0.8624589565851879\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo con los datos nuevos que son los datos de df_test_copy\n",
    "test_predictions, test_true_labels = evaluate_model(model, test_dataloader, device)\n",
    "\n",
    "# Imprimir el reporte de clasificación y la matriz de confusión\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_true_labels, test_predictions))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_true_labels, test_predictions))\n",
    "\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(test_true_labels, test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
